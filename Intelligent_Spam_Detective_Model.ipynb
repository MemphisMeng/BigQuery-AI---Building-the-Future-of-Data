{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 110281,
          "databundleVersionId": 13391012,
          "sourceType": "competition"
        },
        {
          "sourceId": 50392224,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "IeILNPuVF-2d"
      ],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MemphisMeng/BigQuery-AI---Building-the-Future-of-Data/blob/main/Intelligent_Spam_Detective_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "2gtolQk_Fq_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Necessary packages\n"
      ],
      "metadata": {
        "id": "_OXRWnkkFu-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Install all necessary libraries, including BigQuery client\n",
        "# !pip install \"bigframes==2.9.0\"\n",
        "# !pip install \"google-cloud-bigquery[bqstorage,pandas]==3.33.0\"\n",
        "# !pip install \"google-cloud-bigquery-storage==2.30.0\"\n",
        "# !pip install \"pandas==2.2.2\"\n",
        "# !pip install \"protobuf==5.29.1\" \"rich==13.9.2\""
      ],
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "id": "txkPS8eFsgQH"
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "## datasets\n",
        "\n",
        "\n",
        "---\n",
        "The referenced dataset is publicly accessible on kaggle, credit ML team in UCI.\n"
      ],
      "metadata": {
        "id": "IeILNPuVF-2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "I3lULGQlMRBp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "source": [
        "# input datasets\n",
        "import pandas as pd\n",
        "import kagglehub\n",
        "\n",
        "################################################################################################################\n",
        "# ONLY RUN THIS CELL WHEN YOU RUN THIS NOTEBOOK FOR THE FIRST TIME IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.#\n",
        "# kagglehub.login()                                                                                            #\n",
        "################################################################################################################\n",
        "\n",
        "dataset_path = 'uciml/sms-spam-collection-dataset'\n",
        "dataset_directory = kagglehub.dataset_download(dataset_path)\n",
        "sms_df = pd.read_csv(f\"{dataset_directory}/spam.csv\", encoding=\"latin1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wYammMHsgQF",
        "outputId": "d608cbe9-5627-4592-a0d1-21fa72e90823"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'sms-spam-collection-dataset' dataset.\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "# data cleansing\n",
        "## combine all content from the 2nd to 5th column\n",
        "sms_df['message'] = None\n",
        "sms_df['message'].loc[sms_df['Unnamed: 4'].notna()] = \\\n",
        "  sms_df['v2'] + ',' + sms_df['Unnamed: 2'].astype(str) + ',' + sms_df['Unnamed: 3'].astype(str) + ',' + sms_df['Unnamed: 4'].astype(str)\n",
        "\n",
        "sms_df['message'].loc[(sms_df['Unnamed: 4'].isna()) & (sms_df['Unnamed: 3'].notna())] = \\\n",
        "  sms_df['v2'] + ',' + sms_df['Unnamed: 2'].astype(str) + ',' + sms_df['Unnamed: 3'].astype(str)\n",
        "\n",
        "sms_df['message'].loc[(sms_df['Unnamed: 3'].isna()) & (sms_df['Unnamed: 2'].notna())] = \\\n",
        "  sms_df['v2'] + ',' + sms_df['Unnamed: 2'].astype(str)\n",
        "\n",
        "sms_df['message'].loc[sms_df['Unnamed: 2'].isna()] = sms_df['v2']\n",
        "\n",
        "# rename the column to make it meaningful\n",
        "sms_df.rename(columns={'v1': 'label'}, inplace=True)\n",
        "\n",
        "# take the necessary columns\n",
        "sms_df = sms_df[['message', 'label']]"
      ],
      "metadata": {
        "id": "riy8NSqkCuK5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling\n",
        "\n",
        "---\n",
        "The most instinctive approach with the help of BigQuery AI is to ask it whether the give message is a piece of spam or ham, by providing a structured prompt. To do this, a `GeminiTextGenerator` object will be initiated."
      ],
      "metadata": {
        "id": "j9YVthXcFm_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bigframes\n",
        "from bigframes.ml.llm import GeminiTextGenerator\n",
        "\n",
        "PROJECT_ID = \"chatbot-278522\"  # ⚠️ CHANGE THIS to your actual Google Cloud project ID\n",
        "bigframes.options.bigquery.project = PROJECT_ID\n",
        "gemini = GeminiTextGenerator()"
      ],
      "metadata": {
        "id": "bJmyzPcYqJ6O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7c44428e-1d62-4afd-c113-2e37beabe06d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 63d14c09-b3cb-420e-bb65-c7189fca1d66 is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:63d14c09-b3cb-420e-bb65-c7189fca1d66&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 868adc01-87f3-4725-bb0e-4ac0d5550164 is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:868adc01-87f3-4725-bb0e-4ac0d5550164&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each of the messages in the BigQuery DataFrame is going to be questioned: \"`Is the message spam or ham? Please only answer \\\"spam\\\" or \\\"ham\\\" in ONE word.`\""
      ],
      "metadata": {
        "id": "q0ysMn2nsTgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_sms_df = gemini.predict(\n",
        "    sms_df,\n",
        "    prompt=[\"Is the message spam or ham? Please only answer \\\"spam\\\" or \\\"ham\\\" in ONE word.\",\n",
        "            sms_df['message']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "collapsed": true,
        "id": "mvgNtyQqyjbf",
        "outputId": "eeb56a96-6875-4261-dbfb-78d6450d91f0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Load job 07b98bac-8aa7-4819-9f6f-c280915d43d4 is DONE. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:07b98bac-8aa7-4819-9f6f-c280915d43d4&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Load job cac7a959-9c50-4324-901c-8e2480953a55 is DONE. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:cac7a959-9c50-4324-901c-8e2480953a55&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job baff47a8-8ed2-44be-968a-81b7fff12bcc is DONE. 1.1 MB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:baff47a8-8ed2-44be-968a-81b7fff12bcc&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = (gemini_sms_df['label'] == gemini_sms_df['ml_generate_text_llm_result'].str.strip()).sum() / len(gemini_sms_df)\n",
        "print(f\"Accuracy of Gemini model: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ97qYkAzaK6",
        "outputId": "9a6ae586-3dcb-4f8a-b0c8-15c370bf48e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Gemini model: 0.7541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the accuracy performance, there is space for optimization. To more accurately fit the pattern(s) between the texts and the label of spam/ham, plain texts are embedded into multi-dimensional vectors by `bigframes.ml.llm.TextEmbeddingGenerator` to prepare my further in-house modeling."
      ],
      "metadata": {
        "id": "7A8oEusxtMgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bigframes.ml.llm import TextEmbeddingGenerator\n",
        "from bigframes.ml.preprocessing import LabelEncoder\n",
        "\n",
        "## preprocessing\n",
        "# message is \"X\"\n",
        "embedder = TextEmbeddingGenerator()\n",
        "embedded_X = embedder.predict(sms_df['message'])\n",
        "print(\"Input texts are successfully vectorized!\")\n",
        "# label is \"y\"\n",
        "transformer = LabelEncoder(max_categories=2)\n",
        "transformed_y = transformer.fit_transform(sms_df['label'])\n",
        "print(\"Outcome labels are successfully encoded!\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "uKMTRiudsgQN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "outputId": "e771a702-e8fc-4535-bc9e-e1745e7712b0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 2a20e905-dfb4-4f17-ba9c-43ebfb9bd1a6 is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:2a20e905-dfb4-4f17-ba9c-43ebfb9bd1a6&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Load job cdbb1900-1a5d-42e0-96b7-0c1568cd08b9 is DONE. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:cdbb1900-1a5d-42e0-96b7-0c1568cd08b9&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job bee98223-6725-4b29-9eef-e23a9dca2cbf is DONE. 506.5 kB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:bee98223-6725-4b29-9eef-e23a9dca2cbf&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input texts are successfully vectorized!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Load job 4b1a60dc-46d1-42d8-9826-7685b2122ce0 is DONE. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:4b1a60dc-46d1-42d8-9826-7685b2122ce0&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job c2569006-ec35-4b50-a6c8-19b936d1d5fb is DONE. 73.2 kB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:c2569006-ec35-4b50-a6c8-19b936d1d5fb&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 3cb50d57-6767-440f-ad40-8ed13467b467 is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:3cb50d57-6767-440f-ad40-8ed13467b467&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Load job 87108102-050a-4783-8f58-36306da744ba is DONE. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:87108102-050a-4783-8f58-36306da744ba&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 0f1af588-d636-48c1-bc71-47be5cf31912 is DONE. 73.2 kB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:0f1af588-d636-48c1-bc71-47be5cf31912&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outcome labels are successfully encoded!\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to the non-linear relationship between the inputs (natural language texts) and outputs (labels), and its robustness against the overfitting, **XGBoost** is chosen as the underlying classification algorithm, which is encapsulated and provided by `bigframes.ml`."
      ],
      "metadata": {
        "id": "5hbJpV_loXz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bigframes.ml.ensemble import XGBClassifier\n",
        "from bigframes.ml.model_selection import cross_validate\n",
        "\n",
        "KFold = 3\n",
        "\n",
        "clf = XGBClassifier()\n",
        "cv_results = cross_validate(clf, X=embedded_X['ml_generate_embedding_result'], y=transformed_y['labelencoded_label'], cv=KFold)['test_score']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "TqX4iWS5CSCS",
        "outputId": "770f4913-8ac7-4935-9eaa-12f08dda75c8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 94a90890-3531-4564-ab73-6a0697e92d24 is DONE. 34.4 MB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:94a90890-3531-4564-ab73-6a0697e92d24&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 09045650-1e39-49f8-9fed-89fadabd0ecb is DONE. 13.6 GB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:09045650-1e39-49f8-9fed-89fadabd0ecb&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 5d73cc53-ccc9-44de-9131-3ce0465bee13 is DONE. 34.5 MB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:5d73cc53-ccc9-44de-9131-3ce0465bee13&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 2e2af965-b089-4b1c-ad0d-335ee36f5d19 is DONE. 34.4 MB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:2e2af965-b089-4b1c-ad0d-335ee36f5d19&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job ee94f0d2-f05e-4567-b6cd-1d37168c6226 is DONE. 7.2 GB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:ee94f0d2-f05e-4567-b6cd-1d37168c6226&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 99930322-5b0d-4031-b4e9-b0762feadb9e is DONE. 34.5 MB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:99930322-5b0d-4031-b4e9-b0762feadb9e&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 10a7790d-0422-4b1e-ac93-73be8cd975be is DONE. 34.4 MB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:10a7790d-0422-4b1e-ac93-73be8cd975be&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job c4f5cba7-ceef-4ec8-93ba-2018b08db2f1 is DONE. 13.2 GB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:c4f5cba7-ceef-4ec8-93ba-2018b08db2f1&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 73f9989d-bcd2-4165-a143-f6934d3c9f19 is DONE. 34.5 MB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:73f9989d-bcd2-4165-a143-f6934d3c9f19&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_accuracy = sum([cv_result['accuracy'] for cv_result in cv_results]) / KFold\n",
        "print(f\"Average accuracy of self-trained XGBoost Classification: {avg_accuracy[0]:.4f}\")"
      ],
      "metadata": {
        "id": "nqj8-x5CwrZC",
        "outputId": "d8fe22bd-23a3-4f2d-cd9b-3129aa0d1525",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average accuracy of self-trained XGBoost Classification: 0.9833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that a rise of accuracy is witnessed, it is safe to say that the trained model is reliable to be reused. So we can retrain the model on the full dataset and save it on further usage."
      ],
      "metadata": {
        "id": "Oy1x5qkiTkGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# re-train through the full dataset\n",
        "clf.fit(\n",
        "    X=embedded_X['ml_generate_embedding_result'],\n",
        "    y=transformed_y['labelencoded_label']\n",
        ")\n",
        "clf.to_gbq(model_name='chatbot-278522.retail_Business_Intelligence.xgboost_spam_detector')\n",
        "# alone with other models\n",
        "embedder.to_gbq(model_name='chatbot-278522.retail_Business_Intelligence.embedder')\n",
        "transformer.to_gbq(model_name='chatbot-278522.retail_Business_Intelligence.label_encoder')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "v1X_Xh7IQrVA",
        "outputId": "d34e23e3-eb2b-43e5-e7d2-dfd370fe5023"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Copy job 2376f95e-2aa6-44db-89be-861a1138b840 is DONE. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:2376f95e-2aa6-44db-89be-861a1138b840&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 36b8ec05-ab46-42ac-afa0-7bd39b33490e is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:36b8ec05-ab46-42ac-afa0-7bd39b33490e&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Copy job 9a111c0b-5dd2-4cd5-8ab3-48896c48291a is DONE. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:9a111c0b-5dd2-4cd5-8ab3-48896c48291a&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder(max_categories=2, min_frequency=0)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is BigQuery-native (re)usage of the pre-trained XGBoost model: I let `GeminiTextGenerator` to randomly generate some SMS texts, and saved them to a dataset hosted on BigQuery. This simulates a data source that needs to be verified if each message is spam or ham."
      ],
      "metadata": {
        "id": "FBk6MSmyUBys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bigframes.pandas as bpd\n",
        "\n",
        "generated_df = gemini.predict(\n",
        "    bpd.DataFrame({\"dummy\": range(5)}),  # 5 rows → 5 generations,\n",
        "    prompt=\"\"\"\n",
        "    Generate one and ONLY one SMS text message someone might receive.\n",
        "    It can be a piece of SPAM or HAM (legitimate text).\n",
        "    It doesn't have to be an ice breaker, instead, something that usually only appear in the middle of a conversation works.\n",
        "    Just output the messages for me.\n",
        "    Don't put any other text before or after the message, for example, \"Here are a few distinct examples:\".\n",
        "    Make sure the message is eligible to English speakers, not truncated and distinct.\n",
        "    You may add some emotional elements to the tone, perhaps emojis would help.\n",
        "    \"\"\"\n",
        ")\n",
        "generated_df.rename(columns={'ml_generate_text_llm_result': 'generated_message'}, inplace=True)\n",
        "generated_df[['generated_message']].to_gbq(\n",
        "    destination_table='chatbot-278522.retail_Business_Intelligence.generated_sms',\n",
        "    if_exists='replace')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "E0eYKdEwUAiu",
        "outputId": "4c2203dc-5bf6-4856-8da3-096acbf057c6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job bf5bc20b-c61c-42ab-937e-f3c9bbb14839 is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:bf5bc20b-c61c-42ab-937e-f3c9bbb14839&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 038c3bdf-3f92-457f-8087-784b5fb57225 is DONE. 806 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:038c3bdf-3f92-457f-8087-784b5fb57225&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'chatbot-278522.retail_Business_Intelligence.generated_sms'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The trained XGBoosted model can tell whether or not the generated texts are spam or ham. We can do this in a completely BigQuery-native manner."
      ],
      "metadata": {
        "id": "_yminN49mONC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "DATASET_ID = \"retail_Business_Intelligence\"        # This will be created for you\n",
        "client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "query = f'''\n",
        "  SELECT content as message,\n",
        "  CASE predicted_labelencoded_label\n",
        "  WHEN 1 THEN 'ham'\n",
        "  WHEN 0 THEN 'spam'\n",
        "  END AS label\n",
        "  FROM\n",
        "  ML.PREDICT(\n",
        "    MODEL `{PROJECT_ID}.{DATASET_ID}.xgboost_spam_detector`,\n",
        "    (\n",
        "      SELECT ml_generate_embedding_result, content\n",
        "      FROM ML.GENERATE_EMBEDDING( MODEL `{PROJECT_ID}.{DATASET_ID}.embedder`,\n",
        "          (SELECT generated_message AS content FROM `{PROJECT_ID}`.`{DATASET_ID}`.`generated_sms`)\n",
        "          )\n",
        "    )\n",
        "  ) gen\n",
        "'''\n",
        "\n",
        "try:\n",
        "    result_df = client.query(query).to_dataframe()\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error accessing BigQuery: {e}\")\n",
        "result_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iGCu1-TknAaY",
        "outputId": "468aa034-ad08-442a-f9ff-90fcb915603a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             message label\n",
              "0  Okay, I'm on my way, ETA 15 mins 🏃‍♀️ Traffic'...   ham\n",
              "1  Okay, sounds good! I'll give you one single SM...   ham\n",
              "2  Okay, got it.\\n\\nSounds good, I'll bring the c...   ham\n",
              "3  Okay, I'm on my way! 🏃‍♀️ ETA 15 mins. Traffic...   ham\n",
              "4       Okay, I'm on my way! 🏃‍♀️ See you in 10! 😊\\n   ham"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3af58ce8-19e8-40e6-9a7a-4b0e793cab0c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Okay, I'm on my way, ETA 15 mins 🏃‍♀️ Traffic'...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Okay, sounds good! I'll give you one single SM...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Okay, got it.\\n\\nSounds good, I'll bring the c...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Okay, I'm on my way! 🏃‍♀️ ETA 15 mins. Traffic...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Okay, I'm on my way! 🏃‍♀️ See you in 10! 😊\\n</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3af58ce8-19e8-40e6-9a7a-4b0e793cab0c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3af58ce8-19e8-40e6-9a7a-4b0e793cab0c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3af58ce8-19e8-40e6-9a7a-4b0e793cab0c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dfb1e411-e4ee-4e72-a424-a4c237aeadf1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dfb1e411-e4ee-4e72-a424-a4c237aeadf1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dfb1e411-e4ee-4e72-a424-a4c237aeadf1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result_df",
              "summary": "{\n  \"name\": \"result_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Okay, sounds good! I'll give you one single SMS message.\\n\\n> No worries! Just let me know by tomorrow morning so I can finalize the headcount. \\ud83c\\udf55\\ud83c\\udf89\\ud83d\\ude03 Otherwise, they'll donate the extra pizzas to the shelter.\\n\",\n          \"Okay, I'm on my way! \\ud83c\\udfc3\\u200d\\u2640\\ufe0f See you in 10! \\ud83d\\ude0a\\n\",\n          \"Okay, got it.\\n\\nSounds good, I'll bring the chips and dip! \\ud83d\\ude0b You grabbing the drinks?\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# So, is that the end?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Definitely no! With the detecting tech gets more and more sensitive, the scammers player harder and harder to get. One of their tricks is to put what used to be their plain text messages in an image so that the traditional detection will be circumvented. In this section, I am going to explore the image comprehending and identifying capacities of GCP, with which a multi-modal spam detector will be developed and implemented."
      ],
      "metadata": {
        "id": "wgoKk7APJb47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = 'tiharajayawickrama/spam-misleading-images-dataset'\n",
        "dataset_directory = kagglehub.dataset_download(dataset_path)"
      ],
      "metadata": {
        "id": "2RbOmg3aKtB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_directory"
      ],
      "metadata": {
        "id": "_ezCHWIlK_a3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}