{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 110281,
          "databundleVersionId": 13391012,
          "sourceType": "competition"
        },
        {
          "sourceId": 50392224,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_OXRWnkkFu-z"
      ],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MemphisMeng/BigQuery-AI---Building-the-Future-of-Data/blob/main/Intelligent_Spam_Detective_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "2gtolQk_Fq_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Necessary packages\n"
      ],
      "metadata": {
        "id": "_OXRWnkkFu-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Install all necessary libraries, including BigQuery client\n",
        "# !pip install \"bigframes==2.9.0\"\n",
        "# !pip install \"google-cloud-bigquery[bqstorage,pandas]==3.33.0\"\n",
        "# !pip install \"google-cloud-bigquery-storage==2.30.0\"\n",
        "# !pip install \"pandas==2.2.2\"\n",
        "# !pip install \"protobuf==5.29.1\" \"rich==13.9.2\""
      ],
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "id": "txkPS8eFsgQH"
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "## datasets\n",
        "\n",
        "\n",
        "---\n",
        "The referenced dataset is publicly accessible on kaggle, credit ML team in UCI.\n"
      ],
      "metadata": {
        "id": "IeILNPuVF-2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "I3lULGQlMRBp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "source": [
        "# input datasets\n",
        "import pandas as pd\n",
        "import kagglehub\n",
        "\n",
        "################################################################################################################\n",
        "# ONLY RUN THIS CELL WHEN YOU RUN THIS NOTEBOOK FOR THE FIRST TIME IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.#\n",
        "# kagglehub.login()                                                                                            #\n",
        "################################################################################################################\n",
        "\n",
        "dataset_path = 'uciml/sms-spam-collection-dataset'\n",
        "dataset_directory = kagglehub.dataset_download(dataset_path)\n",
        "sms_df = pd.read_csv(f\"{dataset_directory}/spam.csv\", encoding=\"latin1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wYammMHsgQF",
        "outputId": "d608cbe9-5627-4592-a0d1-21fa72e90823"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'sms-spam-collection-dataset' dataset.\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "# data cleansing\n",
        "## combine all content from the 2nd to 5th column\n",
        "sms_df['message'] = None\n",
        "sms_df['message'].loc[sms_df['Unnamed: 4'].notna()] = \\\n",
        "  sms_df['v2'] + ',' + sms_df['Unnamed: 2'].astype(str) + ',' + sms_df['Unnamed: 3'].astype(str) + ',' + sms_df['Unnamed: 4'].astype(str)\n",
        "\n",
        "sms_df['message'].loc[(sms_df['Unnamed: 4'].isna()) & (sms_df['Unnamed: 3'].notna())] = \\\n",
        "  sms_df['v2'] + ',' + sms_df['Unnamed: 2'].astype(str) + ',' + sms_df['Unnamed: 3'].astype(str)\n",
        "\n",
        "sms_df['message'].loc[(sms_df['Unnamed: 3'].isna()) & (sms_df['Unnamed: 2'].notna())] = \\\n",
        "  sms_df['v2'] + ',' + sms_df['Unnamed: 2'].astype(str)\n",
        "\n",
        "sms_df['message'].loc[sms_df['Unnamed: 2'].isna()] = sms_df['v2']\n",
        "\n",
        "# rename the column to make it meaningful\n",
        "sms_df.rename(columns={'v1': 'label'}, inplace=True)\n",
        "\n",
        "# take the necessary columns\n",
        "sms_df = sms_df[['message', 'label']]"
      ],
      "metadata": {
        "id": "riy8NSqkCuK5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling\n",
        "\n",
        "---\n",
        "The most instinctive approach with the help of BigQuery AI is to ask it whether the give message is a piece of spam or ham, by providing a structured prompt. To do this, a `GeminiTextGenerator` object will be initiated."
      ],
      "metadata": {
        "id": "j9YVthXcFm_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bigframes\n",
        "from bigframes.ml.llm import GeminiTextGenerator\n",
        "\n",
        "PROJECT_ID = \"chatbot-278522\"  # ⚠️ CHANGE THIS to your actual Google Cloud project ID\n",
        "bigframes.options.bigquery.project = PROJECT_ID\n",
        "gemini = GeminiTextGenerator()"
      ],
      "metadata": {
        "id": "bJmyzPcYqJ6O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7c44428e-1d62-4afd-c113-2e37beabe06d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 63d14c09-b3cb-420e-bb65-c7189fca1d66 is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:63d14c09-b3cb-420e-bb65-c7189fca1d66&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 868adc01-87f3-4725-bb0e-4ac0d5550164 is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:868adc01-87f3-4725-bb0e-4ac0d5550164&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each of the messages in the BigQuery DataFrame is going to be questioned: \"`Is the message spam or ham? Please only answer \\\"spam\\\" or \\\"ham\\\" in ONE word.`\""
      ],
      "metadata": {
        "id": "q0ysMn2nsTgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_sms_df = gemini.predict(\n",
        "    sms_df,\n",
        "    prompt=[\"Is the message spam or ham? Please only answer \\\"spam\\\" or \\\"ham\\\" in ONE word.\",\n",
        "            sms_df['message']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "collapsed": true,
        "id": "mvgNtyQqyjbf",
        "outputId": "eeb56a96-6875-4261-dbfb-78d6450d91f0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Load job 07b98bac-8aa7-4819-9f6f-c280915d43d4 is DONE. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:07b98bac-8aa7-4819-9f6f-c280915d43d4&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Load job cac7a959-9c50-4324-901c-8e2480953a55 is DONE. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:cac7a959-9c50-4324-901c-8e2480953a55&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job baff47a8-8ed2-44be-968a-81b7fff12bcc is DONE. 1.1 MB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:baff47a8-8ed2-44be-968a-81b7fff12bcc&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = (gemini_sms_df['label'] == gemini_sms_df['ml_generate_text_llm_result'].str.strip()).sum() / len(gemini_sms_df)\n",
        "print(f\"Accuracy of Gemini model: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ97qYkAzaK6",
        "outputId": "9a6ae586-3dcb-4f8a-b0c8-15c370bf48e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Gemini model: 0.7541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the accuracy performance, there is space for optimization. To more accurately fit the pattern(s) between the texts and the label of spam/ham, plain texts are embedded into multi-dimensional vectors by `bigframes.ml.llm.TextEmbeddingGenerator` to prepare my further in-house modeling."
      ],
      "metadata": {
        "id": "7A8oEusxtMgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bigframes.ml.llm import TextEmbeddingGenerator\n",
        "from bigframes.ml.preprocessing import LabelEncoder\n",
        "\n",
        "## preprocessing\n",
        "# message is \"X\"\n",
        "embedder = TextEmbeddingGenerator()\n",
        "embedded_X = embedder.predict(sms_df['message'])\n",
        "print(\"Input texts are successfully vectorized!\")\n",
        "# label is \"y\"\n",
        "transformer = LabelEncoder(max_categories=2)\n",
        "transformed_y = transformer.fit_transform(sms_df['label'])\n",
        "print(\"Outcome labels are successfully encoded!\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "uKMTRiudsgQN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "outputId": "e771a702-e8fc-4535-bc9e-e1745e7712b0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 2a20e905-dfb4-4f17-ba9c-43ebfb9bd1a6 is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:2a20e905-dfb4-4f17-ba9c-43ebfb9bd1a6&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Load job cdbb1900-1a5d-42e0-96b7-0c1568cd08b9 is DONE. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:cdbb1900-1a5d-42e0-96b7-0c1568cd08b9&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job bee98223-6725-4b29-9eef-e23a9dca2cbf is DONE. 506.5 kB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:bee98223-6725-4b29-9eef-e23a9dca2cbf&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input texts are successfully vectorized!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Load job 4b1a60dc-46d1-42d8-9826-7685b2122ce0 is DONE. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:4b1a60dc-46d1-42d8-9826-7685b2122ce0&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job c2569006-ec35-4b50-a6c8-19b936d1d5fb is DONE. 73.2 kB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:c2569006-ec35-4b50-a6c8-19b936d1d5fb&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 3cb50d57-6767-440f-ad40-8ed13467b467 is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:3cb50d57-6767-440f-ad40-8ed13467b467&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Load job 87108102-050a-4783-8f58-36306da744ba is DONE. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:87108102-050a-4783-8f58-36306da744ba&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 0f1af588-d636-48c1-bc71-47be5cf31912 is DONE. 73.2 kB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:0f1af588-d636-48c1-bc71-47be5cf31912&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outcome labels are successfully encoded!\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to the non-linear relationship between the inputs (natural language texts) and outputs (labels), and its robustness against the overfitting, **XGBoost** is chosen as the underlying classification algorithm, which is encapsulated and provided by `bigframes.ml`."
      ],
      "metadata": {
        "id": "5hbJpV_loXz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bigframes.ml.ensemble import XGBClassifier\n",
        "from bigframes.ml.model_selection import cross_validate\n",
        "\n",
        "KFold = 3\n",
        "\n",
        "clf = XGBClassifier()\n",
        "cv_results = cross_validate(clf, X=embedded_X['ml_generate_embedding_result'], y=transformed_y['labelencoded_label'], cv=KFold)['test_score']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "TqX4iWS5CSCS",
        "outputId": "770f4913-8ac7-4935-9eaa-12f08dda75c8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 94a90890-3531-4564-ab73-6a0697e92d24 is DONE. 34.4 MB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:94a90890-3531-4564-ab73-6a0697e92d24&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 09045650-1e39-49f8-9fed-89fadabd0ecb is DONE. 13.6 GB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:09045650-1e39-49f8-9fed-89fadabd0ecb&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 5d73cc53-ccc9-44de-9131-3ce0465bee13 is DONE. 34.5 MB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:5d73cc53-ccc9-44de-9131-3ce0465bee13&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 2e2af965-b089-4b1c-ad0d-335ee36f5d19 is DONE. 34.4 MB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:2e2af965-b089-4b1c-ad0d-335ee36f5d19&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job ee94f0d2-f05e-4567-b6cd-1d37168c6226 is DONE. 7.2 GB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:ee94f0d2-f05e-4567-b6cd-1d37168c6226&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 99930322-5b0d-4031-b4e9-b0762feadb9e is DONE. 34.5 MB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:99930322-5b0d-4031-b4e9-b0762feadb9e&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 10a7790d-0422-4b1e-ac93-73be8cd975be is DONE. 34.4 MB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:10a7790d-0422-4b1e-ac93-73be8cd975be&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job c4f5cba7-ceef-4ec8-93ba-2018b08db2f1 is DONE. 13.2 GB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:c4f5cba7-ceef-4ec8-93ba-2018b08db2f1&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job 73f9989d-bcd2-4165-a143-f6934d3c9f19 is DONE. 34.5 MB processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:73f9989d-bcd2-4165-a143-f6934d3c9f19&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_accuracy = sum([cv_result['accuracy'] for cv_result in cv_results]) / KFold\n",
        "print(f\"Average accuracy of self-trained XGBoost Classification: {avg_accuracy[0]:.4f}\")"
      ],
      "metadata": {
        "id": "nqj8-x5CwrZC",
        "outputId": "d8fe22bd-23a3-4f2d-cd9b-3129aa0d1525",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average accuracy of self-trained XGBoost Classification: 0.9833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that a rise of accuracy is witnessed, it is safe to say that the trained model is reliable to be reused. So we can retrain the model on the full dataset and save it on further usage."
      ],
      "metadata": {
        "id": "Oy1x5qkiTkGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# re-train through the full dataset\n",
        "clf.fit(\n",
        "    X=embedded_X['ml_generate_embedding_result'],\n",
        "    y=transformed_y['labelencoded_label']\n",
        ")\n",
        "clf.to_gbq(model_name='chatbot-278522.retail_Business_Intelligence.xgboost_spam_detector')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "v1X_Xh7IQrVA",
        "outputId": "eefbb651-0f0d-4736-b5b7-726b9d6e5609"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Copy job 1b9b3370-e972-490b-99ea-42b32bb61f79 is DONE. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:1b9b3370-e972-490b-99ea-42b32bb61f79&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(booster='GBTREE', tree_method='AUTO')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is BigQuery-native (re)usage of the pre-trained XGBoost model: I let `GeminiTextGenerator` to randomly generate some SMS texts, and saved them to a dataset hosted on BigQuery. This simulates a data source that needs to be verified if each message is spam or ham."
      ],
      "metadata": {
        "id": "FBk6MSmyUBys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bigframes.pandas as bpd\n",
        "\n",
        "generated_df = gemini.predict(\n",
        "    bpd.DataFrame({\"dummy\": range(5)}),  # 5 rows → 5 generations,\n",
        "    prompt=\"\"\"\n",
        "    Generate one and ONLY one SMS text message someone might receive.\n",
        "    It can be a piece of SPAM or HAM (legitimate text).\n",
        "    Just output the messages for me.\n",
        "    Don't put any other text before or after the message, for example, \"Here are a few distinct examples:\".\n",
        "    Make sure the message is eligible to English speakers, not truncated and distinct.\n",
        "    You may add some emotional elements to the tone, perhaps emojis would help.\n",
        "    \"\"\"\n",
        ")\n",
        "generated_df.rename(columns={'ml_generate_text_llm_result': 'generated_message'}, inplace=True)\n",
        "generated_df[['generated_message']].to_gbq(\n",
        "    destination_table='chatbot-278522.retail_Business_Intelligence.generated_sms',\n",
        "    if_exists='replace')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "E0eYKdEwUAiu",
        "outputId": "d43cc402-cf59-4c55-e62b-eb1f2c16c64c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Query job bf4bddc0-4473-459d-8fbe-35c44e2dd14e is RUNNING. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=chatbot-278522&j=bq:US:bf4bddc0-4473-459d-8fbe-35c44e2dd14e&page=queryresults\">Open Job</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The trained XGBoosted model can tell whether or not the generated texts are spam or ham. We can do this in a completely BigQuery-native manner."
      ],
      "metadata": {
        "id": "_yminN49mONC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iGCu1-TknAaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# So, is that the end?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Definitely no! With the detecting tech gets more and more sensitive, the scammers player harder and harder to get. One of their tricks is to put what used to be their plain text messages in an image so that the traditional detection will be circumvented. In this section, I am going to explore the image comprehending and identifying capacities of GCP, with which a multi-modal spam detector will be developed and implemented."
      ],
      "metadata": {
        "id": "wgoKk7APJb47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = 'tiharajayawickrama/spam-misleading-images-dataset'\n",
        "dataset_directory = kagglehub.dataset_download(dataset_path)"
      ],
      "metadata": {
        "id": "2RbOmg3aKtB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_directory"
      ],
      "metadata": {
        "id": "_ezCHWIlK_a3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}